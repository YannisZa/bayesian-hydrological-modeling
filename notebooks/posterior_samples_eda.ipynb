{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import theano\n",
    "from theano import *\n",
    "import theano.tensor as tt\n",
    "from theano.compile.ops import as_op\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import argparse\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import sys  \n",
    "\n",
    "sys.path.insert(0, '/Users/Yannis/code/fibe2-mini-project/models')\n",
    "from LinearReservoirModel import LinearReservoirModel as LRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory and project root directory\n",
    "cwd = os.getcwd()\n",
    "rd = os.path.join(cwd.split('fibe2-mini-project/', 1)[0])\n",
    "if not rd.endswith('fibe2-mini-project'):\n",
    "    rd = os.path.join(cwd.split('fibe2-mini-project/', 1)[0],'fibe2-mini-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0data = pd.read_csv(os.path.join(rd,'data','output','simulations','linear_reservoir_simulation.csv'))\n",
    "model1data = pd.read_csv(os.path.join(rd,'data','output','simulations','nonlinear_reservoir_simulation.csv'))\n",
    "model2data = pd.read_csv(os.path.join(rd,'data','output','simulations','hymod_simulation.csv'))\n",
    "\n",
    "# Store net net_rainfall\n",
    "nr = model0data['net_rainfall'].values.tolist()\n",
    "n = len(nr)\n",
    "\n",
    "\n",
    "with open(os.path.join(rd,'data','output','simulations/linear_reservoir_simulation_true_parameters.json'), 'r') as f:\n",
    "    lrm_true_params = json.load(f)\n",
    "lrm_true_args = Namespace(**lrm_true_params)\n",
    "\n",
    "with open(os.path.join(rd,'data','output','simulations/nonlinear_reservoir_simulation_true_parameters.json'), 'r') as f:\n",
    "    nlrm_true_params = json.load(f)\n",
    "nlrm_true_args = Namespace(**nlrm_true_params)\n",
    "\n",
    "with open(os.path.join(rd,'data','output','simulations/hymod_simulation_true_parameters.json'), 'r') as f:\n",
    "    hymod_true_params = json.load(f)\n",
    "hymod_true_args = Namespace(**hymod_true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LRM(nr,lrm_true_args)\n",
    "\n",
    "@as_op(itypes=[tt.dscalar], otypes=[tt.dmatrix])\n",
    "def th_forward_model(param1):\n",
    "    parameter_list = [param1]\n",
    "\n",
    "    th_states = lrm.simulate(parameter_list,lrm_true_args.fatconv)\n",
    "    return th_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to files\n",
    "csv_file = os.path.join(rd,'data','output','posterior_samples/linear_reservoir_samples.csv')\n",
    "\n",
    "LRMtrace_LRMdata_file = os.path.join(rd,'data','output','posterior_samples/linear_reservoir_samples_LRMdata_trace.pickle')\n",
    "LRMmodel_LRMdata_file = os.path.join(rd,'data','output','posterior_samples/linear_reservoir_samples_LRMdata_model.pickle')\n",
    "\n",
    "LRMtrace_NLRMdata_file = os.path.join(rd,'data','output','posterior_samples/linear_reservoir_samples_NLRMdata_trace.pickle')\n",
    "LRMmodel_NLRMdata_file = os.path.join(rd,'data','output','posterior_samples/linear_reservoir_samples_NLRMdata_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "results = pd.read_csv(csv_file)\n",
    "\n",
    "LRMtrace_LRMdata = open(LRMtrace_LRMdata_file,\"rb\")\n",
    "LRMmodel_LRMdata = open(LRMmodel_LRMdata_file,\"rb\")\n",
    "LRMtrace_LRMdata = pickle.load(LRMtrace_LRMdata)\n",
    "LRMmodel_LRMdata = pickle.load(LRMmodel_LRMdata)\n",
    "\n",
    "\n",
    "LRMtrace_NLRMdata = open(LRMtrace_NLRMdata_file,\"rb\")\n",
    "LRMmodel_NLRMdata = open(LRMmodel_NLRMdata_file,\"rb\")\n",
    "LRMtrace_NLRMdata = pickle.load(LRMtrace_NLRMdata)\n",
    "LRMmodel_NLRMdata = pickle.load(LRMmodel_NLRMdata)\n",
    "\n",
    "traces = {\"LRM\":LRMtrace_LRMdata,\"NLRM\":LRMtrace_NLRMdata}\n",
    "models = {\"LRM\":LRMmodel_LRMdata,\"NLRM\":LRMmodel_NLRMdata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['current_model','true_model','parameter','marginal_likelihood','mean', 'sd', 'mc_error', 'hpd_2.5', 'hpd_97.5']\n",
    "results = pd.DataFrame(columns=keys)\n",
    "for mi in ['LRM','NLRM']:#,'HYMOD']:\n",
    "    vals = np.append(np.array(['LRM',mi,'k',models[mi].marginal_likelihood]),pm.summary(traces[mi], ['k']).values[0])\n",
    "    results = results.append(dict(zip(keys, vals)),ignore_index=True)\n",
    "    vals = np.append(np.array(['LRM',mi,'sigma',models[mi].marginal_likelihood]),pm.summary(traces[mi], ['sigma']).values[0])\n",
    "    results = results.append(dict(zip(keys, vals)),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlrm_true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hymod_true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of posterior samples\n",
    "npostsamples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(9, 6))\n",
    "ppc_0 = pm.sample_posterior_predictive(LRMtrace_LRMdata, npostsamples, LRMmodel_LRMdata, size=(n, 20))\n",
    "ppc_1 = pm.sample_posterior_predictive(LRMtrace_NLRMdata, npostsamples, LRMmodel_NLRMdata, size=(n, 20))\n",
    "for m_0, m_1 in zip(ppc_0['Q_obs'].T, ppc_1['Q_obs'].T):\n",
    "    pm.kdeplot(np.mean(m_0, 0), ax=ax, plot_kwargs={'color':'C0'})\n",
    "    pm.kdeplot(np.mean(m_1, 0), ax=ax, plot_kwargs={'color':'C1'})\n",
    "ax.plot([], label='LRM model on LRM data')\n",
    "ax.plot([], label='LRM model on NLRM data')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_xlabel(u'Q', fontsize=14)\n",
    "ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(figsize=(9, 6))\n",
    "# ppc_0 = pm.sample_posterior_predictive(traces[0], 100, models[0], size=(len(y), 20))\n",
    "# ppc_1 = pm.sample_posterior_predictive(traces[1], 100, models[1], size=(len(y), 20))\n",
    "# for m_0, m_1 in zip(ppc_0['yl'].T, ppc_1['yl'].T):\n",
    "#     pm.kdeplot(np.mean(m_0, 0), ax=ax, plot_kwargs={'color':'C0'})\n",
    "#     pm.kdeplot(np.mean(m_1, 0), ax=ax, plot_kwargs={'color':'C1'})\n",
    "# ax.plot([], label='model_0')\n",
    "# ax.plot([], label='model_1')\n",
    "# ax.legend(fontsize=14)\n",
    "# ax.set_xlabel(u'Î¸', fontsize=14)\n",
    "# ax.set_yticks([]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "mini-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
